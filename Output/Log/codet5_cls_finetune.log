nohup: ignoring input
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
==================================================
Program Starting with Parameters:
==================================================Model Name: codet5

Program Starting with Parameters:Dataset Name: CR

Model Name: codet5==================================================

Dataset Name: CR

==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
==================================================
Program Starting with Parameters:
Model Name: codet5
Dataset Name: CR
==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
==================================================
Program Starting with Parameters:
Model Name: codet5
Dataset Name: CR
==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
==================================================
Program Starting with Parameters:
Model Name: codet5
Dataset Name: CR
==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
==================================================
Program Starting with Parameters:
Model Name: codet5
Dataset Name: CR
==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
==================================================
Program Starting with Parameters:
Model Name: codet5
Dataset Name: CR
==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
==================================================
Program Starting with Parameters:
Model Name: codet5
Dataset Name: CR
==================================================

05/24/2025 11:55:55 - INFO - __main__ -   Start Training
05/24/2025 11:55:55 - INFO - __main__ -   Training/eval parameters: model_name_or_path=../ACR_Model_Saved/codet5/originalModel/, output_dir=../ACR_Model_Saved/codet5/cls/, dev_filename=../ACR_Dataset/CR/cls/cls-valid.jsonl, train_filename=../ACR_Dataset/CR/cls/
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 5
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 7
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 2
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 6
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 1
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 4
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 3
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - INFO - torch.distributed.distributed_c10d -   Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 3, global rank: 3, world size: 8
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 1, global rank: 1, world size: 8
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 2, global rank: 2, world size: 8
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 5, global rank: 5, world size: 8
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 4, global rank: 4, world size: 8
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 6, global rank: 6, world size: 8
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 0, global rank: 0, world size: 8
05/24/2025 11:55:56 - WARNING - Model._1_BaseTrainer.base_trainer -   Process rank: 7, global rank: 7, world size: 8
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   ==========
05/24/2025 11:55:56 - INFO - Model._1_BaseTrainer.utils -   loaded model path:../ACR_Model_Saved/codet5/originalModel/
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/root/anaconda3/envs/transformer/lib/python3.8/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/24/2025 11:56:02 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:02 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:02 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:02 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of codet5Model were not initialized from the model checkpoint at ../ACR_Model_Saved/codet5/originalModel/ and are newly initialized: ['cls_head.bias', 'cls_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
05/24/2025 11:56:03 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:03 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:03 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:04 - INFO - Model._1_BaseTrainer.utils -   Resizing token embeddings from 32128 to 32216
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 7, device: cuda:7, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 5, device: cuda:5, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 4, device: cuda:4, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, cpu count: 40
05/24/2025 11:56:09 - WARNING - Model._1_BaseTrainer.configs -   Process rank: 6, device: cuda:6, n_gpu: 1, distributed training: True, cpu count: 40
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:56:11 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-2rb.exps
05/24/2025 11:56:34 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:34 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:34 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:34 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:39 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:39 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:39 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:39 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:56:54 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:56:55 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:56:55 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:56:55 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:57:00 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:57:00 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:57:01 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:57:01 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-0rb.exps
05/24/2025 11:57:17 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:18 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:23 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:24 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:24 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:24 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:24 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:31 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:57:40 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:41 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:46 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:47 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:47 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:47 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:47 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:57:53 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-1rb.exps
05/24/2025 11:58:07 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:09 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:10 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:13 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:14 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:14 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:14 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:20 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:31 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:33 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:34 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:37 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:37 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:37 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:38 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:43 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-train-chunk-3rb.exps
05/24/2025 11:58:55 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:58:57 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:01 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:03 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:03 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:03 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:04 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:07 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
../ACR_Dataset/CR/cls/
05/24/2025 11:59:16 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:18 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:22 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:24 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:24 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:24 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:26 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
../ACR_Dataset/CR/cls/
05/24/2025 11:59:27 - INFO - Model._1_BaseTrainer.utils -   Loading examples from ../ACR_Dataset/CR/cls/cls-validrb.exps
05/24/2025 11:59:33 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:34 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:38 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:38 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:40 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:41 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:42 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:43 - INFO - Model._1_BaseTrainer.utils -   Convert examples to features...
05/24/2025 11:59:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 11:59:54 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 11:59:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 11:59:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:00:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:00:02 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:00:02 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:00:03 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:05:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 100/120000, Loss: 0.6879
05/24/2025 12:10:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 200/120000, Loss: 0.6932
05/24/2025 12:16:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 300/120000, Loss: 0.6913
05/24/2025 12:21:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 400/120000, Loss: 0.6873
05/24/2025 12:26:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 500/120000, Loss: 0.6228
05/24/2025 12:32:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 600/120000, Loss: 0.5578
05/24/2025 12:37:29 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 700/120000, Loss: 0.5519
05/24/2025 12:42:50 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 800/120000, Loss: 0.5311
05/24/2025 12:48:12 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 900/120000, Loss: 0.5302
05/24/2025 12:53:33 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 1000/120000, Loss: 0.5354
05/24/2025 12:58:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 1, Step: 1100/120000, Loss: 0.5239
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 12:59:31 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:04:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1200/120000, Loss: 0.5187
05/24/2025 13:09:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1300/120000, Loss: 0.5066
05/24/2025 13:15:08 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1400/120000, Loss: 0.5142
05/24/2025 13:20:29 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1500/120000, Loss: 0.5061
05/24/2025 13:25:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1600/120000, Loss: 0.4992
05/24/2025 13:31:12 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1700/120000, Loss: 0.4946
05/24/2025 13:36:33 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1800/120000, Loss: 0.5027
05/24/2025 13:41:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 1900/120000, Loss: 0.5045
05/24/2025 13:47:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 2000/120000, Loss: 0.4959
05/24/2025 13:52:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 2100/120000, Loss: 0.5089
05/24/2025 13:57:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 2, Step: 2200/120000, Loss: 0.4972
05/24/2025 13:58:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 13:58:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:03:26 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2300/120000, Loss: 0.4920
05/24/2025 14:08:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2400/120000, Loss: 0.4865
05/24/2025 14:14:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2500/120000, Loss: 0.4895
05/24/2025 14:19:30 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2600/120000, Loss: 0.4848
05/24/2025 14:24:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2700/120000, Loss: 0.4656
05/24/2025 14:30:12 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2800/120000, Loss: 0.4696
05/24/2025 14:35:33 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 2900/120000, Loss: 0.4829
05/24/2025 14:40:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 3000/120000, Loss: 0.4856
05/24/2025 14:46:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 3100/120000, Loss: 0.4766
05/24/2025 14:51:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 3200/120000, Loss: 0.4974
05/24/2025 14:56:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 3, Step: 3300/120000, Loss: 0.4872
05/24/2025 14:58:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 14:58:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 15:02:27 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 3400/120000, Loss: 0.4742
05/24/2025 15:07:48 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 3500/120000, Loss: 0.4709
05/24/2025 15:13:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 3600/120000, Loss: 0.4694
05/24/2025 15:15:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1576  348]
 [ 876 1105]]
05/24/2025 15:15:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6866, Precision: 0.7605, Recall: 0.5578, F1: 0.6436
05/24/2025 15:15:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 3600: 0.6436
05/24/2025 15:15:52 - INFO - Model._1_BaseTrainer.classification_trainer -   New best model saved to ../ACR_Model_Saved/codet5/cls/checkpoint-3600-0.6436
05/24/2025 15:21:13 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 3700/120000, Loss: 0.4720
05/24/2025 15:26:35 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 3800/120000, Loss: 0.4550
05/24/2025 15:31:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 3900/120000, Loss: 0.4374
05/24/2025 15:37:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 4000/120000, Loss: 0.4628
05/24/2025 15:42:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 4100/120000, Loss: 0.4780
05/24/2025 15:48:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 4200/120000, Loss: 0.4504
05/24/2025 15:53:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 4300/120000, Loss: 0.4763
05/24/2025 15:58:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 4, Step: 4400/120000, Loss: 0.4641
05/24/2025 16:00:37 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:37 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:37 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:37 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:37 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:38 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:38 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:00:38 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 16:04:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 4500/120000, Loss: 0.4646
05/24/2025 16:09:35 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 4600/120000, Loss: 0.4538
05/24/2025 16:14:56 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 4700/120000, Loss: 0.4625
05/24/2025 16:20:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 4800/120000, Loss: 0.4565
05/24/2025 16:25:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 4900/120000, Loss: 0.4480
05/24/2025 16:31:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 5000/120000, Loss: 0.4322
05/24/2025 16:36:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 5100/120000, Loss: 0.4547
05/24/2025 16:41:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 5200/120000, Loss: 0.4700
05/24/2025 16:47:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 5300/120000, Loss: 0.4363
05/24/2025 16:52:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 5400/120000, Loss: 0.4705
05/24/2025 16:57:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 5, Step: 5500/120000, Loss: 0.4529
05/24/2025 17:00:05 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:05 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:00:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:03:17 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 5600/120000, Loss: 0.4496
05/24/2025 17:08:38 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 5700/120000, Loss: 0.4417
05/24/2025 17:13:59 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 5800/120000, Loss: 0.4403
05/24/2025 17:19:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 5900/120000, Loss: 0.4461
05/24/2025 17:24:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6000/120000, Loss: 0.4304
05/24/2025 17:30:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6100/120000, Loss: 0.4152
05/24/2025 17:35:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6200/120000, Loss: 0.4268
05/24/2025 17:40:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6300/120000, Loss: 0.4495
05/24/2025 17:46:08 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6400/120000, Loss: 0.4249
05/24/2025 17:51:29 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6500/120000, Loss: 0.4447
05/24/2025 17:56:50 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 6, Step: 6600/120000, Loss: 0.4380
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 17:59:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 18:02:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 6700/120000, Loss: 0.4304
05/24/2025 18:07:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 6800/120000, Loss: 0.4258
05/24/2025 18:13:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 6900/120000, Loss: 0.4224
05/24/2025 18:18:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7000/120000, Loss: 0.4205
05/24/2025 18:23:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7100/120000, Loss: 0.4099
05/24/2025 18:29:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7200/120000, Loss: 0.3905
05/24/2025 18:31:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1524  400]
 [ 812 1169]]
05/24/2025 18:31:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6896, Precision: 0.7451, Recall: 0.5901, F1: 0.6586
05/24/2025 18:31:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 7200: 0.6586
05/24/2025 18:31:50 - INFO - Model._1_BaseTrainer.classification_trainer -   New best model saved to ../ACR_Model_Saved/codet5/cls/checkpoint-7200-0.6586
05/24/2025 18:37:11 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7300/120000, Loss: 0.3839
05/24/2025 18:42:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7400/120000, Loss: 0.3872
05/24/2025 18:47:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7500/120000, Loss: 0.3678
05/24/2025 18:53:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7600/120000, Loss: 0.3962
05/24/2025 18:58:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 7, Step: 7700/120000, Loss: 0.3652
05/24/2025 19:01:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:01:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 19:04:06 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 7800/120000, Loss: 0.3762
05/24/2025 19:09:28 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 7900/120000, Loss: 0.3916
05/24/2025 19:14:49 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8000/120000, Loss: 0.3920
05/24/2025 19:20:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8100/120000, Loss: 0.3746
05/24/2025 19:25:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8200/120000, Loss: 0.3713
05/24/2025 19:30:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8300/120000, Loss: 0.3518
05/24/2025 19:36:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8400/120000, Loss: 0.3353
05/24/2025 19:41:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8500/120000, Loss: 0.3550
05/24/2025 19:46:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8600/120000, Loss: 0.3467
05/24/2025 19:52:19 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8700/120000, Loss: 0.3554
05/24/2025 19:57:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 8, Step: 8800/120000, Loss: 0.3400
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:01:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 20:03:11 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 8900/120000, Loss: 0.3184
05/24/2025 20:08:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9000/120000, Loss: 0.3329
05/24/2025 20:13:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9100/120000, Loss: 0.3462
05/24/2025 20:19:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9200/120000, Loss: 0.3366
05/24/2025 20:24:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9300/120000, Loss: 0.3301
05/24/2025 20:29:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9400/120000, Loss: 0.3139
05/24/2025 20:35:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9500/120000, Loss: 0.2956
05/24/2025 20:40:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9600/120000, Loss: 0.2964
05/24/2025 20:46:01 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9700/120000, Loss: 0.3121
05/24/2025 20:51:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9800/120000, Loss: 0.3088
05/24/2025 20:56:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 9, Step: 9900/120000, Loss: 0.2955
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:00:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 21:02:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10000/120000, Loss: 0.2702
05/24/2025 21:07:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10100/120000, Loss: 0.2978
05/24/2025 21:12:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10200/120000, Loss: 0.2984
05/24/2025 21:18:19 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10300/120000, Loss: 0.2923
05/24/2025 21:23:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10400/120000, Loss: 0.2865
05/24/2025 21:29:02 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10500/120000, Loss: 0.2628
05/24/2025 21:34:24 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10600/120000, Loss: 0.2591
05/24/2025 21:39:45 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10700/120000, Loss: 0.2528
05/24/2025 21:45:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10800/120000, Loss: 0.2536
05/24/2025 21:47:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1332  592]
 [ 708 1273]]
05/24/2025 21:47:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6671, Precision: 0.6826, Recall: 0.6426, F1: 0.6620
05/24/2025 21:47:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 10800: 0.6620
05/24/2025 21:47:48 - INFO - Model._1_BaseTrainer.classification_trainer -   New best model saved to ../ACR_Model_Saved/codet5/cls/checkpoint-10800-0.6620
05/24/2025 21:53:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 10900/120000, Loss: 0.1640
05/24/2025 21:58:30 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 10, Step: 11000/120000, Loss: 0.1253
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:02:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 22:04:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11100/120000, Loss: 0.1336
05/24/2025 22:09:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11200/120000, Loss: 0.2801
05/24/2025 22:14:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11300/120000, Loss: 0.2844
05/24/2025 22:20:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11400/120000, Loss: 0.3003
05/24/2025 22:25:26 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11500/120000, Loss: 0.2758
05/24/2025 22:30:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11600/120000, Loss: 0.2588
05/24/2025 22:36:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11700/120000, Loss: 0.2398
05/24/2025 22:41:30 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11800/120000, Loss: 0.2503
05/24/2025 22:46:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 11900/120000, Loss: 0.2437
05/24/2025 22:52:13 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 12000/120000, Loss: 0.2415
05/24/2025 22:57:34 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 11, Step: 12100/120000, Loss: 0.2131
05/24/2025 23:02:28 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:28 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:28 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:28 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:28 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:28 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:29 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:02:29 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/24/2025 23:03:05 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12200/120000, Loss: 0.1925
05/24/2025 23:08:26 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12300/120000, Loss: 0.2818
05/24/2025 23:13:48 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12400/120000, Loss: 0.2911
05/24/2025 23:19:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12500/120000, Loss: 0.3006
05/24/2025 23:24:31 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12600/120000, Loss: 0.2832
05/24/2025 23:29:52 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12700/120000, Loss: 0.2632
05/24/2025 23:35:13 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12800/120000, Loss: 0.2457
05/24/2025 23:40:35 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 12900/120000, Loss: 0.2404
05/24/2025 23:45:56 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 13000/120000, Loss: 0.2463
05/24/2025 23:51:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 13100/120000, Loss: 0.2452
05/24/2025 23:56:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 12, Step: 13200/120000, Loss: 0.2102
05/25/2025 00:01:58 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:01:59 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 00:02:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13300/120000, Loss: 0.1903
05/25/2025 00:07:31 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13400/120000, Loss: 0.2676
05/25/2025 00:12:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13500/120000, Loss: 0.2879
05/25/2025 00:18:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13600/120000, Loss: 0.3093
05/25/2025 00:23:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13700/120000, Loss: 0.2892
05/25/2025 00:29:02 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13800/120000, Loss: 0.2530
05/25/2025 00:34:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 13900/120000, Loss: 0.2396
05/25/2025 00:39:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 14000/120000, Loss: 0.2382
05/25/2025 00:45:08 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 14100/120000, Loss: 0.2500
05/25/2025 00:50:29 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 14200/120000, Loss: 0.2346
05/25/2025 00:55:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 14300/120000, Loss: 0.2042
05/25/2025 01:01:12 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 13, Step: 14400/120000, Loss: 0.1881
05/25/2025 01:03:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1337  587]
 [ 686 1295]]
05/25/2025 01:03:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6740, Precision: 0.6881, Recall: 0.6537, F1: 0.6705
05/25/2025 01:03:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 14400: 0.6705
05/25/2025 01:03:54 - INFO - Model._1_BaseTrainer.classification_trainer -   New best model saved to ../ACR_Model_Saved/codet5/cls/checkpoint-14400-0.6705
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:04:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 01:09:24 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 14500/120000, Loss: 0.2586
05/25/2025 01:14:45 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 14600/120000, Loss: 0.2868
05/25/2025 01:20:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 14700/120000, Loss: 0.2933
05/25/2025 01:25:28 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 14800/120000, Loss: 0.2812
05/25/2025 01:30:50 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 14900/120000, Loss: 0.2452
05/25/2025 01:36:11 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 15000/120000, Loss: 0.2372
05/25/2025 01:41:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 15100/120000, Loss: 0.2291
05/25/2025 01:46:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 15200/120000, Loss: 0.2325
05/25/2025 01:52:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 15300/120000, Loss: 0.2350
05/25/2025 01:57:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 15400/120000, Loss: 0.2067
05/25/2025 02:02:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 14, Step: 15500/120000, Loss: 0.1856
05/25/2025 02:03:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:03:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 02:08:27 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 15600/120000, Loss: 0.2484
05/25/2025 02:13:49 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 15700/120000, Loss: 0.2858
05/25/2025 02:19:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 15800/120000, Loss: 0.2959
05/25/2025 02:24:31 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 15900/120000, Loss: 0.2885
05/25/2025 02:29:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16000/120000, Loss: 0.2452
05/25/2025 02:35:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16100/120000, Loss: 0.2364
05/25/2025 02:40:35 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16200/120000, Loss: 0.2403
05/25/2025 02:45:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16300/120000, Loss: 0.2392
05/25/2025 02:51:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16400/120000, Loss: 0.2225
05/25/2025 02:56:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16500/120000, Loss: 0.2074
05/25/2025 03:02:01 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 15, Step: 16600/120000, Loss: 0.1878
05/25/2025 03:03:16 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:16 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:16 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:16 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:16 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:16 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:03:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 03:07:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 16700/120000, Loss: 0.2447
05/25/2025 03:12:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 16800/120000, Loss: 0.2833
05/25/2025 03:18:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 16900/120000, Loss: 0.3012
05/25/2025 03:23:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17000/120000, Loss: 0.2943
05/25/2025 03:28:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17100/120000, Loss: 0.2703
05/25/2025 03:34:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17200/120000, Loss: 0.2353
05/25/2025 03:39:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17300/120000, Loss: 0.2326
05/25/2025 03:45:01 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17400/120000, Loss: 0.2345
05/25/2025 03:50:23 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17500/120000, Loss: 0.2348
05/25/2025 03:55:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17600/120000, Loss: 0.2062
05/25/2025 04:01:06 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 16, Step: 17700/120000, Loss: 0.1836
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:46 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:02:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 04:06:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 17800/120000, Loss: 0.2296
05/25/2025 04:11:58 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 17900/120000, Loss: 0.2735
05/25/2025 04:17:19 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18000/120000, Loss: 0.2828
05/25/2025 04:19:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1306  618]
 [ 671 1310]]
05/25/2025 04:19:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6699, Precision: 0.6795, Recall: 0.6613, F1: 0.6702
05/25/2025 04:19:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 18000: 0.6702
05/25/2025 04:25:12 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18100/120000, Loss: 0.2185
05/25/2025 04:30:33 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18200/120000, Loss: 0.1860
05/25/2025 04:35:56 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18300/120000, Loss: 0.1669
05/25/2025 04:41:18 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18400/120000, Loss: 0.1528
05/25/2025 04:46:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18500/120000, Loss: 0.1435
05/25/2025 04:52:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18600/120000, Loss: 0.1477
05/25/2025 04:57:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18700/120000, Loss: 0.1280
05/25/2025 05:02:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 17, Step: 18800/120000, Loss: 0.1010
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:04:50 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 05:08:13 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 18900/120000, Loss: 0.1919
05/25/2025 05:13:35 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19000/120000, Loss: 0.2752
05/25/2025 05:18:56 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19100/120000, Loss: 0.3004
05/25/2025 05:24:17 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19200/120000, Loss: 0.2828
05/25/2025 05:29:38 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19300/120000, Loss: 0.2657
05/25/2025 05:35:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19400/120000, Loss: 0.2335
05/25/2025 05:40:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19500/120000, Loss: 0.2271
05/25/2025 05:45:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19600/120000, Loss: 0.2368
05/25/2025 05:51:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19700/120000, Loss: 0.2221
05/25/2025 05:56:28 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19800/120000, Loss: 0.2209
05/25/2025 06:01:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 18, Step: 19900/120000, Loss: 0.1948
05/25/2025 06:04:23 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:23 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:23 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:23 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:23 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:23 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:04:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 06:07:23 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20000/120000, Loss: 0.2223
05/25/2025 06:12:45 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20100/120000, Loss: 0.2794
05/25/2025 06:18:06 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20200/120000, Loss: 0.2797
05/25/2025 06:23:27 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20300/120000, Loss: 0.2799
05/25/2025 06:28:49 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20400/120000, Loss: 0.2638
05/25/2025 06:34:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20500/120000, Loss: 0.2345
05/25/2025 06:39:31 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20600/120000, Loss: 0.2204
05/25/2025 06:44:52 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20700/120000, Loss: 0.2369
05/25/2025 06:50:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20800/120000, Loss: 0.2313
05/25/2025 06:55:35 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 20900/120000, Loss: 0.2304
05/25/2025 07:00:57 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 19, Step: 21000/120000, Loss: 0.1811
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:03:55 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 07:06:27 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21100/120000, Loss: 0.1921
05/25/2025 07:11:49 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21200/120000, Loss: 0.2733
05/25/2025 07:17:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21300/120000, Loss: 0.2914
05/25/2025 07:22:31 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21400/120000, Loss: 0.2812
05/25/2025 07:27:52 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21500/120000, Loss: 0.2627
05/25/2025 07:33:14 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21600/120000, Loss: 0.2344
05/25/2025 07:35:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1302  622]
 [ 668 1313]]
05/25/2025 07:35:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6697, Precision: 0.6786, Recall: 0.6628, F1: 0.6706
05/25/2025 07:35:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 21600: 0.6706
05/25/2025 07:35:56 - INFO - Model._1_BaseTrainer.classification_trainer -   New best model saved to ../ACR_Model_Saved/codet5/cls/checkpoint-21600-0.6706
05/25/2025 07:41:17 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21700/120000, Loss: 0.1470
05/25/2025 07:46:38 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21800/120000, Loss: 0.1384
05/25/2025 07:51:59 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 21900/120000, Loss: 0.1440
05/25/2025 07:57:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 22000/120000, Loss: 0.1378
05/25/2025 08:02:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 20, Step: 22100/120000, Loss: 0.0997
05/25/2025 08:06:05 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 08:08:12 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22200/120000, Loss: 0.1424
05/25/2025 08:13:34 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22300/120000, Loss: 0.2727
05/25/2025 08:18:55 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22400/120000, Loss: 0.2830
05/25/2025 08:24:16 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22500/120000, Loss: 0.2696
05/25/2025 08:29:37 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22600/120000, Loss: 0.2689
05/25/2025 08:34:59 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22700/120000, Loss: 0.2473
05/25/2025 08:40:20 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22800/120000, Loss: 0.2320
05/25/2025 08:45:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 22900/120000, Loss: 0.2302
05/25/2025 08:51:03 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 23000/120000, Loss: 0.2326
05/25/2025 08:56:24 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 23100/120000, Loss: 0.2192
05/25/2025 09:01:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 21, Step: 23200/120000, Loss: 0.1984
05/25/2025 09:05:35 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:35 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:05:36 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 09:07:17 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23300/120000, Loss: 0.1746
05/25/2025 09:12:38 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23400/120000, Loss: 0.2814
05/25/2025 09:18:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23500/120000, Loss: 0.2846
05/25/2025 09:23:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23600/120000, Loss: 0.2732
05/25/2025 09:28:42 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23700/120000, Loss: 0.2761
05/25/2025 09:34:04 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23800/120000, Loss: 0.2419
05/25/2025 09:39:25 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 23900/120000, Loss: 0.2300
05/25/2025 09:44:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 24000/120000, Loss: 0.2283
05/25/2025 09:50:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 24100/120000, Loss: 0.2255
05/25/2025 09:55:30 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 24200/120000, Loss: 0.2200
05/25/2025 10:00:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 22, Step: 24300/120000, Loss: 0.1876
05/25/2025 10:05:06 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:05:07 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 10:06:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 24400/120000, Loss: 0.1778
05/25/2025 10:11:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 24500/120000, Loss: 0.2795
05/25/2025 10:17:05 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 24600/120000, Loss: 0.2802
05/25/2025 10:22:27 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 24700/120000, Loss: 0.2785
05/25/2025 10:27:49 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 24800/120000, Loss: 0.2774
05/25/2025 10:33:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 24900/120000, Loss: 0.2315
05/25/2025 10:38:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 25000/120000, Loss: 0.2368
05/25/2025 10:43:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 25100/120000, Loss: 0.2186
05/25/2025 10:49:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 25200/120000, Loss: 0.2253
05/25/2025 10:51:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1293  631]
 [ 664 1317]]
05/25/2025 10:51:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6684, Precision: 0.6761, Recall: 0.6648, F1: 0.6704
05/25/2025 10:51:47 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 25200: 0.6704
05/25/2025 10:57:08 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 25300/120000, Loss: 0.1338
05/25/2025 11:02:29 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 23, Step: 25400/120000, Loss: 0.1017
05/25/2025 11:07:09 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:07:10 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 11:08:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 25500/120000, Loss: 0.1011
05/25/2025 11:13:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 25600/120000, Loss: 0.2656
05/25/2025 11:18:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 25700/120000, Loss: 0.2690
05/25/2025 11:24:06 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 25800/120000, Loss: 0.2750
05/25/2025 11:29:28 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 25900/120000, Loss: 0.2663
05/25/2025 11:34:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 26000/120000, Loss: 0.2385
05/25/2025 11:40:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 26100/120000, Loss: 0.2357
05/25/2025 11:45:36 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 26200/120000, Loss: 0.2246
05/25/2025 11:50:58 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 26300/120000, Loss: 0.2215
05/25/2025 11:56:19 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 26400/120000, Loss: 0.2199
05/25/2025 12:01:40 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 24, Step: 26500/120000, Loss: 0.1922
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:06:47 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 12:07:11 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 26600/120000, Loss: 0.1872
05/25/2025 12:12:33 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 26700/120000, Loss: 0.2589
05/25/2025 12:17:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 26800/120000, Loss: 0.2774
05/25/2025 12:23:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 26900/120000, Loss: 0.2898
05/25/2025 12:28:37 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27000/120000, Loss: 0.2718
05/25/2025 12:33:58 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27100/120000, Loss: 0.2436
05/25/2025 12:39:19 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27200/120000, Loss: 0.2331
05/25/2025 12:44:41 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27300/120000, Loss: 0.2209
05/25/2025 12:50:02 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27400/120000, Loss: 0.2258
05/25/2025 12:55:23 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27500/120000, Loss: 0.2132
05/25/2025 13:00:45 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27600/120000, Loss: 0.1866
05/25/2025 13:06:06 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 25, Step: 27700/120000, Loss: 0.1805
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:17 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:06:18 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 13:11:37 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 27800/120000, Loss: 0.2624
05/25/2025 13:16:59 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 27900/120000, Loss: 0.2763
05/25/2025 13:22:20 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28000/120000, Loss: 0.2913
05/25/2025 13:27:41 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28100/120000, Loss: 0.2694
05/25/2025 13:33:03 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28200/120000, Loss: 0.2330
05/25/2025 13:38:24 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28300/120000, Loss: 0.2324
05/25/2025 13:43:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28400/120000, Loss: 0.2272
05/25/2025 13:49:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28500/120000, Loss: 0.2309
05/25/2025 13:54:29 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28600/120000, Loss: 0.2236
05/25/2025 13:59:50 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28700/120000, Loss: 0.1984
05/25/2025 14:05:11 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 26, Step: 28800/120000, Loss: 0.1770
05/25/2025 14:07:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1308  616]
 [ 679 1302]]
05/25/2025 14:07:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6684, Precision: 0.6788, Recall: 0.6572, F1: 0.6679
05/25/2025 14:07:44 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 28800: 0.6679
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:21 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:08:22 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 14:13:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 28900/120000, Loss: 0.2403
05/25/2025 14:18:37 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29000/120000, Loss: 0.2755
05/25/2025 14:23:58 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29100/120000, Loss: 0.2844
05/25/2025 14:29:20 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29200/120000, Loss: 0.2779
05/25/2025 14:34:41 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29300/120000, Loss: 0.2416
05/25/2025 14:40:02 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29400/120000, Loss: 0.2345
05/25/2025 14:45:24 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29500/120000, Loss: 0.2245
05/25/2025 14:50:45 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29600/120000, Loss: 0.2282
05/25/2025 14:56:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29700/120000, Loss: 0.2209
05/25/2025 15:01:28 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29800/120000, Loss: 0.2025
05/25/2025 15:06:51 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 27, Step: 29900/120000, Loss: 0.1716
05/25/2025 15:07:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:53 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:54 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:07:54 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 15:12:22 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30000/120000, Loss: 0.2298
05/25/2025 15:17:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30100/120000, Loss: 0.2844
05/25/2025 15:23:05 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30200/120000, Loss: 0.2785
05/25/2025 15:28:26 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30300/120000, Loss: 0.2798
05/25/2025 15:33:48 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30400/120000, Loss: 0.2288
05/25/2025 15:39:09 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30500/120000, Loss: 0.2262
05/25/2025 15:44:30 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30600/120000, Loss: 0.2302
05/25/2025 15:49:52 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30700/120000, Loss: 0.2281
05/25/2025 15:55:13 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30800/120000, Loss: 0.2165
05/25/2025 16:00:34 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 30900/120000, Loss: 0.2012
05/25/2025 16:05:56 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 28, Step: 31000/120000, Loss: 0.1816
05/25/2025 16:07:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:24 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:07:25 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 16:11:27 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31100/120000, Loss: 0.2254
05/25/2025 16:16:48 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31200/120000, Loss: 0.2739
05/25/2025 16:22:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31300/120000, Loss: 0.2663
05/25/2025 16:27:31 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31400/120000, Loss: 0.2741
05/25/2025 16:32:52 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31500/120000, Loss: 0.2458
05/25/2025 16:38:15 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31600/120000, Loss: 0.2266
05/25/2025 16:43:37 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31700/120000, Loss: 0.2172
05/25/2025 16:49:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31800/120000, Loss: 0.2280
05/25/2025 16:54:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 31900/120000, Loss: 0.2192
05/25/2025 16:59:43 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 32000/120000, Loss: 0.2090
05/25/2025 17:05:06 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 29, Step: 32100/120000, Loss: 0.1756
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:00 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:07:01 - INFO - Model._1_BaseTrainer.classification_trainer -   batch size: 10
05/25/2025 17:10:39 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32200/120000, Loss: 0.2194
05/25/2025 17:16:00 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32300/120000, Loss: 0.2687
05/25/2025 17:21:21 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32400/120000, Loss: 0.2760
05/25/2025 17:23:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Confusion Matrix:[[1289  635]
 [ 652 1329]]
05/25/2025 17:23:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Eval Results - ACC: 0.6704, Precision: 0.6767, Recall: 0.6709, F1: 0.6738
05/25/2025 17:23:54 - INFO - Model._1_BaseTrainer.classification_trainer -   Validation Accuracy at step 32400: 0.6738
05/25/2025 17:24:04 - INFO - Model._1_BaseTrainer.classification_trainer -   New best model saved to ../ACR_Model_Saved/codet5/cls/checkpoint-32400-0.6738
05/25/2025 17:29:24 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32500/120000, Loss: 0.2008
05/25/2025 17:34:46 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32600/120000, Loss: 0.1751
05/25/2025 17:40:07 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32700/120000, Loss: 0.1547
05/25/2025 17:45:28 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32800/120000, Loss: 0.1356
05/25/2025 17:50:49 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 32900/120000, Loss: 0.1302
05/25/2025 17:56:10 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 33000/120000, Loss: 0.1328
05/25/2025 18:01:32 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 33100/120000, Loss: 0.1167
05/25/2025 18:06:53 - INFO - Model._1_BaseTrainer.classification_trainer -   Epoch: 30, Step: 33200/120000, Loss: 0.0905
05/25/2025 18:09:05 - INFO - Model._1_BaseTrainer.classification_trainer -   Training finished. Cleaning up resources.
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
Final Model Name: codet5
Final Dataset Name: CR
